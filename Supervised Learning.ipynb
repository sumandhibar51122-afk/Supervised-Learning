{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1. inear Regression (SLR)? Explain its purpose?\n",
        "\n",
        "Simple Linear Regression (SLR) is a statistical method used to model the relationship between two variables â€” one independent variable (X) and one dependent variable (Y) â€” by fitting a straight line to the observed data.\n",
        "\n",
        "ðŸ”¹ Purpose of Simple Linear Regression:\n",
        "\n",
        "The main purposes are:\n",
        "\n",
        "To understand relationships:\n",
        "\n",
        "It helps determine whether and how strongly two variables are related.\n",
        "\n",
        "Example: How does a personâ€™s height (X) affect their weight (Y)?\n",
        "\n",
        "To make predictions:\n",
        "\n",
        "Once the relationship is known, you can use the equation to predict the value of the dependent variable for a given independent variable.\n",
        "\n",
        "Example: Predicting sales (Y) based on advertising expenditure (X).\n",
        "\n",
        "To quantify the effect of X on Y:\n",
        "\n",
        "The slope (bâ‚) in the regression equation indicates how much Y changes for a one-unit change in X.\n",
        "\n",
        "ðŸ”¹ Mathematical Form:\n",
        "ð‘Œ\n",
        "=\n",
        "ð‘\n",
        "0\n",
        "+\n",
        "ð‘\n",
        "1\n",
        "ð‘‹\n",
        "+\n",
        "ðœ€\n",
        "Y=b\n",
        "0\n",
        "\tâ€‹\n",
        "\n",
        "+b\n",
        "1\n",
        "\tâ€‹\n",
        "\n",
        "X+Îµ\n",
        "\n",
        "Where:\n",
        "\n",
        "ð‘Œ\n",
        "Y = Dependent variable (what you want to predict)\n",
        "\n",
        "ð‘‹\n",
        "X = Independent variable (predictor)\n",
        "\n",
        "ð‘\n",
        "0\n",
        "b\n",
        "0\n",
        "\tâ€‹\n",
        "\n",
        " = Intercept (value of Y when X = 0)\n",
        "\n",
        "ð‘\n",
        "1\n",
        "b\n",
        "1\n",
        "\tâ€‹\n",
        "\n",
        " = Slope (rate of change of Y with respect to X)\n",
        "\n",
        "ðœ€\n",
        "Îµ = Error term (difference between actual and predicted values)\n",
        "\n",
        "ðŸ”¹ Example:\n",
        "\n",
        "Suppose we have data on hours studied (X) and exam scores (Y).\n",
        "After fitting a simple linear regression model, we get:\n",
        "\n",
        "Predicted Score\n",
        "=\n",
        "40\n",
        "+\n",
        "5\n",
        "Ã—\n",
        "(\n",
        "Hours Studied\n",
        ")\n",
        "Predicted Score=40+5Ã—(Hours Studied)\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "The intercept (40) suggests that even with 0 hours studied, a student scores 40 (perhaps due to prior knowledge).\n",
        "\n",
        "The slope (5) means that for every additional hour studied, the score increases by 5 points."
      ],
      "metadata": {
        "id": "0rdGpNVFJaMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Key Assumptions of Simple Linear Regression (SLR):\n",
        "\n",
        "To ensure that the results of a simple linear regression model are valid and reliable, several key assumptions must hold true:\n",
        "\n",
        "ðŸ”¹ 1. Linearity\n",
        "\n",
        "The relationship between the independent variable (X) and the dependent variable (Y) is linear.\n",
        "\n",
        "That means:\n",
        "\n",
        "ð¸\n",
        "(\n",
        "ð‘Œ\n",
        "âˆ£\n",
        "ð‘‹\n",
        ")\n",
        "=\n",
        "ð‘\n",
        "0\n",
        "+\n",
        "ð‘\n",
        "1\n",
        "ð‘‹\n",
        "E(Yâˆ£X)=b\n",
        "0\n",
        "\tâ€‹\n",
        "\n",
        "+b\n",
        "1\n",
        "\tâ€‹\n",
        "\n",
        "X\n",
        "\n",
        "Why it matters: If the true relationship is nonlinear, the linear model will give biased predictions.\n",
        "\n",
        "How to check: Plot X vs. Y (scatter plot). The pattern should look roughly like a straight line.\n",
        "\n",
        "ðŸ”¹ 2. Independence of Errors\n",
        "\n",
        "The residuals (errors) should be independent of each other.\n",
        "\n",
        "Why it matters: Correlated errors (like in time series data) can lead to misleading significance tests.\n",
        "\n",
        "How to check: Use a Durbinâ€“Watson test or plot residuals vs. time/order of observations.\n",
        "\n",
        "ðŸ”¹ 3. Homoscedasticity (Constant Variance of Errors)\n",
        "\n",
        "The variance of the residuals should be constant across all values of X.\n",
        "\n",
        "In other words, the spread of errors should not increase or decrease with X.\n",
        "\n",
        "Why it matters: Unequal variances (heteroscedasticity) make confidence intervals and p-values unreliable.\n",
        "\n",
        "How to check: Plot residuals vs. fitted values â€” the spread should be roughly even (no funnel shape).\n",
        "\n",
        "ðŸ”¹ 4. Normality of Errors\n",
        "\n",
        "The residuals should be approximately normally distributed.\n",
        "\n",
        "Why it matters: This assumption mainly affects hypothesis tests and confidence intervals.\n",
        "\n",
        "How to check: Use a histogram, Qâ€“Q plot, or statistical test (like Shapiroâ€“Wilk) on the residuals.\n",
        "\n",
        "ðŸ”¹ 5. No (or minimal) measurement error in X\n",
        "\n",
        "The independent variable\n",
        "ð‘‹\n",
        "X should be measured accurately.\n",
        "\n",
        "Why it matters: Measurement errors in X can bias the slope estimate.\n",
        "\n",
        "| Assumption                | Meaning                         | Check Method                |\n",
        "| ------------------------- | ------------------------------- | --------------------------- |\n",
        "| Linearity                 | Y changes linearly with X       | Scatter plot (Y vs. X)      |\n",
        "| Independence              | Errors are independent          | Durbinâ€“Watson test          |\n",
        "| Homoscedasticity          | Equal variance of residuals     | Residuals vs. fitted values |\n",
        "| Normality                 | Errors are normally distributed | Qâ€“Q plot or histogram       |\n",
        "| No measurement error in X | X values are accurate           | Ensure data accuracy        |\n"
      ],
      "metadata": {
        "id": "h95dNrUxKAsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question3.Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.\n",
        "\n",
        "The mathematical equation for a Simple Linear Regression (SLR) model is:\n",
        "\n",
        "ð‘Œ\n",
        "=\n",
        "ð‘\n",
        "0\n",
        "+\n",
        "ð‘\n",
        "1\n",
        "ð‘‹\n",
        "+\n",
        "ðœ€\n",
        "Y=b\n",
        "0\n",
        "\tâ€‹\n",
        "\n",
        "+b\n",
        "1\n",
        "\tâ€‹\n",
        "\n",
        "X+Îµ\n",
        "\n",
        "| **Term**        | **Name**                                      | **Meaning / Role**                                                                                                                     |\n",
        "| --------------- | --------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| ( Y )           | **Dependent Variable (Response Variable)**    | The variable we want to predict or explain. Example: exam score, house price, sales, etc.                                              |\n",
        "| ( X )           | **Independent Variable (Predictor Variable)** | The variable used to make predictions or explain changes in ( Y ). Example: hours studied, house size, advertising spend, etc.         |\n",
        "| ( b_0 )         | **Intercept (Constant Term)**                 | The predicted value of ( Y ) when ( X = 0 ). It represents where the regression line crosses the Y-axis.                               |\n",
        "| ( b_1 )         | **Slope (Regression Coefficient)**            | The change in ( Y ) for a one-unit increase in ( X ). It shows the strength and direction of the relationship between ( X ) and ( Y ). |\n",
        "| ( \\varepsilon ) | **Error Term (Residual)**                     | The difference between the actual value and the predicted value of ( Y ). It captures random noise and factors not explained by ( X ). |\n",
        "\n",
        "Example:\n",
        "\n",
        "Suppose we model exam score (Y) based on hours studied (X):\n",
        "\n",
        "Exam Score\n",
        "=\n",
        "40\n",
        "+\n",
        "5\n",
        "Ã—\n",
        "(\n",
        "Hours Studied\n",
        ")\n",
        "+\n",
        "ðœ€\n",
        "Exam Score=40+5Ã—(Hours Studied)+Îµ\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "ð‘\n",
        "0\n",
        "=\n",
        "40\n",
        "b\n",
        "0\n",
        "\tâ€‹\n",
        "\n",
        "=40: A student who studies 0 hours is expected to score 40.\n",
        "\n",
        "ð‘\n",
        "1\n",
        "=\n",
        "5\n",
        "b\n",
        "1\n",
        "\tâ€‹\n",
        "\n",
        "=5: For each additional hour of study, the exam score increases by 5 points (on average).\n",
        "\n",
        "ðœ€\n",
        "Îµ: Accounts for other factors like motivation, teaching quality, or randomness.\n",
        "\n",
        "So, the simple linear regression equation expresses a straight-line relationship between two variables, allowing us to quantify, interpret, and predict outcomes."
      ],
      "metadata": {
        "id": "zd0yTVb0KPPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question4.Provide a real-world example where simple linear regression can be\n",
        "applied.\n",
        "\n",
        "A real estate analyst wants to understand how the size of a house (in square feet) affects its market price.\n",
        "\n",
        "ðŸ”¹ Variables:\n",
        "\n",
        "\n",
        "Independent Variable (X): Size of the house (square feet)\n",
        "\n",
        "\n",
        "Dependent Variable (Y): House price (in dollars)\n",
        "\n",
        "\n",
        "\n",
        "ðŸ”¹ Regression Model:\n",
        "Price=b0+b1Ã—(Size)+Îµ\\text{Price} = b_0 + b_1 \\times (\\text{Size}) + \\varepsilonPrice=b0â€‹+b1â€‹Ã—(Size)+Îµ\n",
        "Where:\n",
        "\n",
        "\n",
        "b0b_0b0â€‹ = Intercept â†’ the estimated price of a house with zero size (theoretical baseline).\n",
        "\n",
        "\n",
        "b1b_1b1â€‹ = Slope â†’ how much the price increases for each additional square foot of area.\n",
        "\n",
        "\n",
        "Îµ\\varepsilonÎµ = Error term â†’ captures other factors affecting price (like location, age, design, etc.).\n",
        "\n",
        "\n",
        "\n",
        "ðŸ”¹ Example Equation:\n",
        "Predicted Price=50,000+150Ã—(Size in sq. ft.)\\text{Predicted Price} = 50{,}000 + 150 \\times (\\text{Size in sq. ft.})Predicted Price=50,000+150Ã—(Size in sq. ft.)\n",
        "Interpretation:\n",
        "\n",
        "\n",
        "A 0 sq. ft. home (theoretically) costs $50,000 (the intercept).\n",
        "\n",
        "\n",
        "For each additional square foot, the price increases by $150 on average.\n",
        "\n",
        "\n",
        "So, for a 2,000 sq. ft. house:\n",
        "Predicted Price=50,000+150Ã—2,000=350,000\\text{Predicted Price} = 50{,}000 + 150 \\times 2{,}000 = 350{,}000Predicted Price=50,000+150Ã—2,000=350,000\n",
        "\n",
        "ðŸ”¹ Why Use SLR Here:\n",
        "\n",
        "\n",
        "It helps real estate agents or buyers estimate prices of homes based on size.\n",
        "\n",
        "\n",
        "It shows the strength and direction of the relationship between house size and price.\n",
        "\n",
        "\n",
        "It can be extended later to multiple linear regression by adding more predictors (like location, age, number of bedrooms, etc.).\n",
        "\n",
        "\n",
        "\n",
        "âœ… In short:\n",
        "Simple Linear Regression can be applied to predict house prices from house size â€” a common, practical use case in real estate analytics."
      ],
      "metadata": {
        "id": "9aqqkbsoKlj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question5.  What is the method of least squares in linear regression?\n",
        "\n",
        "\n",
        "\n",
        "The **Method of Least Squares** is the **most common technique** used to estimate the parameters of a **linear regression model** â€” that is, to find the **best-fitting line** through the data.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Concept:**\n",
        "\n",
        "In simple linear regression, we model the relationship between variables as:\n",
        "\n",
        "[\n",
        "Y = b_0 + b_1X + \\varepsilon\n",
        "]\n",
        "\n",
        "But the true line is unknown.\n",
        "So, we estimate it using sample data as:\n",
        "\n",
        "[\n",
        "\\hat{Y} = \\hat{b}_0 + \\hat{b}_1X\n",
        "]\n",
        "\n",
        "The goal is to find values of **( \\hat{b}_0 )** (intercept) and **( \\hat{b}_1 )** (slope) that make the predicted values (( \\hat{Y} )) as close as possible to the actual values (( Y )).\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **How It Works:**\n",
        "\n",
        "For each data point, the **error (residual)** is:\n",
        "\n",
        "[\n",
        "e_i = Y_i - \\hat{Y}_i\n",
        "]\n",
        "\n",
        "The **Method of Least Squares** minimizes the **sum of the squared residuals**:\n",
        "\n",
        "[\n",
        "\\text{Minimize } S = \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2\n",
        "]\n",
        "\n",
        "Squaring ensures:\n",
        "\n",
        "* All errors are positive.\n",
        "* Larger errors have more impact (theyâ€™re penalized more).\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Mathematical Formulas for Estimates:**\n",
        "\n",
        "After minimizing the squared errors, we get:\n",
        "\n",
        "[\n",
        "\\hat{b}_1 = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2}\n",
        "]\n",
        "\n",
        "[\n",
        "\\hat{b}_0 = \\bar{Y} - \\hat{b}_1\\bar{X}\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( \\bar{X} ) = Mean of X values\n",
        "* ( \\bar{Y} ) = Mean of Y values\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Interpretation:**\n",
        "\n",
        "* The resulting line ( \\hat{Y} = \\hat{b}_0 + \\hat{b}_1X ) is the **best-fitting line** in the **least-squares sense** â€” meaning, it has the **smallest total squared prediction error**.\n",
        "* This line represents the **average trend** of the data.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Example:**\n",
        "\n",
        "If we have data on **hours studied (X)** and **exam score (Y)**,\n",
        "the least squares method finds the line:\n",
        "\n",
        "[\n",
        "\\hat{Y} = 40 + 5X\n",
        "]\n",
        "\n",
        "This means the **predicted score** increases by 5 for every extra hour studied, and 40 is the expected score when X = 0.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **In short:**\n",
        "The **Method of Least Squares** finds the regression line that **minimizes the sum of squared differences** between observed and predicted values â€” giving the **best possible linear fit** to the data.\n"
      ],
      "metadata": {
        "id": "EIwa3P7NKxXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Question6: What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        " â€” this is a key concept in statistics and machine learning!\n",
        "\n",
        "\n",
        "**Logistic Regression** is a **supervised learning algorithm** used for **classification problems**, not regression â€” despite its name.\n",
        "\n",
        "It models the **probability** that a given input belongs to a particular **category (class)**.\n",
        "Most commonly, it is used for **binary classification**, where the outcome variable ( Y ) can take only two values (e.g., 0 or 1, Yes or No, Pass or Fail).\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Mathematical Form:**\n",
        "\n",
        "Instead of predicting ( Y ) directly (like in linear regression), logistic regression predicts the **probability** that ( Y = 1 ), given ( X ):\n",
        "\n",
        "[\n",
        "P(Y = 1 | X) = \\frac{1}{1 + e^{-(b_0 + b_1X)}}\n",
        "]\n",
        "\n",
        "This equation is called the **logistic (sigmoid) function**, which transforms any real number into a value between **0 and 1**.\n",
        "\n",
        "* ( b_0 ) = intercept\n",
        "* ( b_1 ) = coefficient (effect of X on the log-odds of Y)\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Decision Rule:**\n",
        "\n",
        "If ( P(Y = 1 | X) > 0.5 ), predict **1**\n",
        "If ( P(Y = 1 | X) \\le 0.5 ), predict **0**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ **How Logistic Regression Differs from Linear Regression**\n",
        "\n",
        "| **Aspect**               | **Linear Regression**                                                | **Logistic Regression**                                          |\n",
        "| ------------------------ | -------------------------------------------------------------------- | ---------------------------------------------------------------- |\n",
        "| **Purpose**              | Predicts a **continuous** outcome (e.g., sales, income, temperature) | Predicts a **categorical** outcome (e.g., yes/no, spam/not spam) |\n",
        "| **Output**               | Real numbers (âˆ’âˆž to +âˆž)                                              | Probabilities between 0 and 1                                    |\n",
        "| **Equation**             | ( Y = b_0 + b_1X )                                                   | ( P(Y=1) = \\frac{1}{1 + e^{-(b_0 + b_1X)}} )                     |\n",
        "| **Error Term**           | Based on squared differences (Least Squares)                         | Based on **likelihood** (Maximum Likelihood Estimation)          |\n",
        "| **Assumed Relationship** | Linear relationship between X and Y                                  | Linear relationship between X and **log-odds** of Y              |\n",
        "| **Use Cases**            | Predicting prices, weights, or scores                                | Classifying emails, diagnosing diseases, predicting churn        |\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Example:**\n",
        "\n",
        "* **Linear Regression:** Predicting a studentâ€™s **exam score** based on hours studied.\n",
        "  [\n",
        "  \\text{Score} = 40 + 5X\n",
        "  ]\n",
        "\n",
        "* **Logistic Regression:** Predicting whether a student **passes (1)** or **fails (0)** based on hours studied.\n",
        "  [\n",
        "  P(\\text{Pass}) = \\frac{1}{1 + e^{-(b_0 + b_1X)}}\n",
        "  ]\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **In summary:**\n",
        "\n",
        "* **Linear Regression** â†’ Predicts a **continuous value**.\n",
        "* **Logistic Regression** â†’ Predicts a **probability** (and thus a **class**).\n",
        "* Logistic Regression uses a **sigmoid curve** to keep outputs between 0 and 1, making it ideal for **classification tasks**.\n"
      ],
      "metadata": {
        "id": "R67TfeM-L8sJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Question7: Name and briefly describe three common evaluation metrics for regression\n",
        "models.\n",
        "\n",
        "Here are **three common evaluation metrics** used to assess the performance of **regression models**:\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **1. Mean Absolute Error (MAE)**\n",
        "\n",
        "[\n",
        "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |Y_i - \\hat{Y}_i|\n",
        "]\n",
        "\n",
        "**Description:**\n",
        "\n",
        "* Measures the **average absolute difference** between actual ((Y_i)) and predicted ((\\hat{Y}_i)) values.\n",
        "* It shows how much, on average, the predictions deviate from the real values.\n",
        "* **Easy to interpret** because itâ€™s in the same units as the output variable.\n",
        "\n",
        "**Goal:** Lower MAE indicates a better model.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **2. Mean Squared Error (MSE)**\n",
        "\n",
        "[\n",
        "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2\n",
        "]\n",
        "\n",
        "**Description:**\n",
        "\n",
        "* Calculates the **average of the squared differences** between actual and predicted values.\n",
        "* Squaring emphasizes **larger errors**, so models with a few big mistakes get penalized more.\n",
        "\n",
        "**Goal:** Lower MSE means higher accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **3. R-squared (Coefficient of Determination)**\n",
        "\n",
        "[\n",
        "R^2 = 1 - \\frac{\\sum (Y_i - \\hat{Y}_i)^2}{\\sum (Y_i - \\bar{Y})^2}\n",
        "]\n",
        "\n",
        "**Description:**\n",
        "\n",
        "* Indicates how well the regression model **explains the variability** in the target variable.\n",
        "* It shows the **proportion of variance in Y** that can be predicted from X.\n",
        "\n",
        "**Range:**\n",
        "\n",
        "* ( R^2 = 1 ): Perfect fit\n",
        "* ( R^2 = 0 ): Model explains nothing\n",
        "\n",
        "**Goal:** Higher ( R^2 ) means a better fit.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **In summary:**\n",
        "\n",
        "| Metric  | Measures                         | Ideal Value         | Key Point              |\n",
        "| ------- | -------------------------------- | ------------------- | ---------------------- |\n",
        "| **MAE** | Average absolute error           | Lower               | Easy to interpret      |\n",
        "| **MSE** | Average squared error            | Lower               | Penalizes large errors |\n",
        "| **RÂ²**  | Proportion of variance explained | Higher (close to 1) | Indicates model fit    |\n",
        "\n",
        "---\n",
        "\n",
        "Would you like me to include **RMSE (Root Mean Squared Error)** as a fourth metric? Itâ€™s often used alongside these three.\n"
      ],
      "metadata": {
        "id": "pYOV1l_RMiZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "\n",
        "\n",
        "### ðŸ”¹ **Purpose of the R-squared Metric in Regression Analysis**\n",
        "\n",
        "**R-squared (RÂ²)** â€” also known as the **Coefficient of Determination** â€” is a key metric used to **evaluate how well a regression model fits the data**.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Definition:**\n",
        "\n",
        "[\n",
        "R^2 = 1 - \\frac{\\text{Sum of Squared Residuals (SSR)}}{\\text{Total Sum of Squares (SST)}}\n",
        "]\n",
        "\n",
        "or\n",
        "\n",
        "[\n",
        "R^2 = 1 - \\frac{\\sum (Y_i - \\hat{Y}_i)^2}{\\sum (Y_i - \\bar{Y})^2}\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( Y_i ) = Actual values\n",
        "* ( \\hat{Y}_i ) = Predicted values\n",
        "* ( \\bar{Y} ) = Mean of actual values\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Purpose / Interpretation:**\n",
        "\n",
        "* **RÂ² measures the proportion of the variance in the dependent variable (Y)** that is **explained by the independent variable(s)** in the model.\n",
        "* In simple terms, it tells you **how well your model explains the data**.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Values and Meaning:**\n",
        "\n",
        "| **RÂ² Value**    | **Interpretation**                                        |\n",
        "| --------------- | --------------------------------------------------------- |\n",
        "| 1               | Perfect fit â€” model explains 100% of the variation in Y   |\n",
        "| 0               | Model explains none of the variation in Y                 |\n",
        "| Between 0 and 1 | Partial fit â€” higher values mean better explanatory power |\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Example:**\n",
        "\n",
        "If ( R^2 = 0.85 ):\n",
        "âž¡ï¸ The model explains **85% of the variability** in the dependent variable.\n",
        "âž¡ï¸ The remaining **15%** is due to random noise or other factors not captured by the model.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Key Purpose (In Simple Terms):**\n",
        "\n",
        "ðŸ‘‰ **R-squared tells you how good your regression line is at representing your data.**\n",
        "It helps answer:\n",
        "\n",
        "> â€œHow much of the change in Y can be explained by X?â€\n",
        "\n",
        "---\n",
        "\n",
        "### âš ï¸ **Important Note:**\n",
        "\n",
        "* A **high RÂ²** doesnâ€™t always mean the model is good â€” it could be **overfitting**.\n",
        "* Always check **residuals** and other metrics (like MAE or MSE) for a full evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **In summary:**\n",
        "**The purpose of R-squared** is to measure the **goodness of fit** of a regression model â€” that is, **how much of the variation in the dependent variable is explained by the modelâ€™s predictors.**\n"
      ],
      "metadata": {
        "id": "8ELTAIRgQI4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# --- 1. Sample Data ---\n",
        "# Let's create some sample data.\n",
        "# X represents the independent variable (feature)\n",
        "# y represents the dependent variable (target)\n",
        "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "y = np.array([2, 4.1, 5.9, 8, 10.2, 11.8, 14.1, 16, 17.9, 20])\n",
        "\n",
        "# --- 2. Preprocess Data ---\n",
        "# Scikit-learn's LinearRegression model expects X to be a 2D array.\n",
        "# Since we have only one feature, we need to reshape it.\n",
        "# We change it from (10,) to (10, 1)\n",
        "X_reshaped = X.reshape(-1, 1)\n",
        "\n",
        "# --- 3. Create and Fit the Model ---\n",
        "# Initialize the LinearRegression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to our data\n",
        "# This is where the model \"learns\" the best-fit line\n",
        "model.fit(X_reshaped, y)\n",
        "\n",
        "# --- 4. Get the Results ---\n",
        "# The intercept (b0) is the value of y when X is 0\n",
        "intercept = model.intercept_\n",
        "\n",
        "# The slope (b1) is the change in y for a one-unit change in X\n",
        "# model.coef_ is an array, so we take the first element\n",
        "slope = model.coef_[0]\n",
        "\n",
        "# --- 5. Print the Results ---\n",
        "print(\"--- Simple Linear Regression Results ---\")\n",
        "print(f\"Intercept (b0): {intercept:.4f}\")\n",
        "print(f\"Slope (b1):     {slope:.4f}\")\n",
        "print(\"\\nEquation of the line: y = {:.4f} * x + {:.4f}\".format(slope, intercept))\n",
        "\n",
        "# --- Example Prediction (Optional) ---\n",
        "# You can now use the model to make predictions\n",
        "x_new = 11\n",
        "x_new_reshaped = np.array([[x_new]]) # Reshape for prediction\n",
        "y_pred = model.predict(x_new_reshaped)\n",
        "\n",
        "print(f\"\\nPrediction for x = {x_new}: {y_pred[0]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCeJn2obQeHN",
        "outputId": "29890cfd-4c4d-4392-d4a3-3124f64353d9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Simple Linear Regression Results ---\n",
            "Intercept (b0): 0.0333\n",
            "Slope (b1):     1.9939\n",
            "\n",
            "Equation of the line: y = 1.9939 * x + 0.0333\n",
            "\n",
            "Prediction for x = 11: 21.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question10: How do you interpret the coefficients in a simple linear regression model?\n",
        "\n",
        "\n",
        "In a **Simple Linear Regression (SLR)** model, the equation is:\n",
        "\n",
        "[\n",
        "Y = b_0 + b_1X + \\varepsilon\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( Y ) = Dependent (response) variable\n",
        "* ( X ) = Independent (predictor) variable\n",
        "* ( b_0 ) = Intercept\n",
        "* ( b_1 ) = Slope (coefficient of X)\n",
        "* ( \\varepsilon ) = Error term\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Interpretation of the Coefficients:**\n",
        "\n",
        "#### **1. Intercept (( b_0 ))**\n",
        "\n",
        "* Represents the **predicted value of ( Y )** when ( X = 0 ).\n",
        "* It is where the regression line **crosses the Y-axis**.\n",
        "* In real-world terms, it gives the **baseline level** of the dependent variable.\n",
        "\n",
        "**Example:**\n",
        "If ( Y = 40 + 5X ):\n",
        "\n",
        "* When ( X = 0 ), ( Y = 40 ).\n",
        "* Interpretation: Even with 0 hours studied, the expected exam score is 40.\n",
        "\n",
        "âš ï¸ *Note:* Sometimes the intercept may not have a practical meaning (e.g., negative house price when size = 0), but it is still mathematically necessary.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Slope (( b_1 ))**\n",
        "\n",
        "* Represents the **change in ( Y )** for a **one-unit increase in ( X )**, assuming all else is constant.\n",
        "* It tells us both the **direction** and **magnitude** of the relationship between ( X ) and ( Y ).\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* If ( b_1 > 0 ): ( Y ) increases as ( X ) increases (positive relationship).\n",
        "* If ( b_1 < 0 ): ( Y ) decreases as ( X ) increases (negative relationship).\n",
        "\n",
        "**Example:**\n",
        "If ( Y = 40 + 5X ):\n",
        "\n",
        "* The slope ( b_1 = 5 ) means: For every **additional hour studied**, the **exam score increases by 5 points** on average.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… **Summary Table**\n",
        "\n",
        "| Coefficient         | Meaning                                  | Example Interpretation              |\n",
        "| ------------------- | ---------------------------------------- | ----------------------------------- |\n",
        "| ( b_0 ) (Intercept) | Predicted value of ( Y ) when ( X = 0 )  | Base exam score = 40 when hours = 0 |\n",
        "| ( b_1 ) (Slope)     | Change in ( Y ) per unit change in ( X ) | +5 points per extra hour studied    |\n",
        "\n",
        "---\n",
        "\n",
        "**In short:**\n",
        "\n",
        "* **Intercept** â†’ starting point (value of ( Y ) when ( X = 0 ))\n",
        "* **Slope** â†’ rate of change (how much ( Y ) changes for each unit increase in ( X ))\n"
      ],
      "metadata": {
        "id": "U2FkSsS2cFuU"
      }
    }
  ]
}